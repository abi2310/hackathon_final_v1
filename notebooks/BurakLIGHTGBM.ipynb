{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c512d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Einen Ordner hochgehen (du bist in /notebooks, Modell liegt eine Ebene darÃ¼ber)\n",
    "os.chdir(\"..\")\n",
    "\n",
    "# src/ zum Python-Pfad hinzufÃ¼gen\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2454b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spalten im DataFrame:\n",
      "['AuftragsID', 'BauteilID', 'Bauteilbezeichnung', 'Auftragseingang', 'PrioritÃ¤t', 'Auftragsende_SOLL', 'Arbeitsschritt', 'Arbeitsschrittbezeichnung', 'AFO_Start_SOLL', 'AFO_Ende_SOLL', 'AFO_Start_IST', 'AFO_Ende_IST', 'MaschinenID', 'Maschinenbezeichnung', 'Auftragsende_IST', 'process_type', 'possible_next_afo', 'remaining_afo_count', 'expected_total_remaining_hours', 'is_standard_sequence', 'progress_ratio']\n",
      "Original Spalten: ['AuftragsID', 'BauteilID', 'Bauteilbezeichnung', 'Auftragseingang', 'PrioritÃ¤t', 'Auftragsende_SOLL', 'Arbeitsschritt', 'Arbeitsschrittbezeichnung', 'AFO_Start_SOLL', 'AFO_Ende_SOLL', 'AFO_Start_IST', 'AFO_Ende_IST', 'MaschinenID', 'Maschinenbezeichnung', 'Auftragsende_IST', 'process_type', 'possible_next_afo', 'remaining_afo_count', 'expected_total_remaining_hours', 'is_standard_sequence', 'progress_ratio']\n",
      "KATEGORIEN: ['Bauteilbezeichnung', 'Arbeitsschrittbezeichnung', 'Maschinenbezeichnung', 'possible_next_afo']\n",
      "NUMERISCH: ['PrioritÃ¤t', 'Arbeitsschritt', 'process_type', 'remaining_afo_count', 'expected_total_remaining_hours', 'is_standard_sequence', 'progress_ratio', 'Auftragseingang_dow', 'Auftragseingang_hour', 'Auftragseingang_day', 'Auftragseingang_month', 'Auftragseingang_week', 'Auftragsende_SOLL_dow', 'Auftragsende_SOLL_hour', 'Auftragsende_SOLL_day', 'Auftragsende_SOLL_month', 'Auftragsende_SOLL_week', 'AFO_Start_SOLL_dow', 'AFO_Start_SOLL_hour', 'AFO_Start_SOLL_day', 'AFO_Start_SOLL_month', 'AFO_Start_SOLL_week', 'AFO_Ende_SOLL_dow', 'AFO_Ende_SOLL_hour', 'AFO_Ende_SOLL_day', 'AFO_Ende_SOLL_month', 'AFO_Ende_SOLL_week', 'AFO_Start_IST_dow', 'AFO_Start_IST_hour', 'AFO_Start_IST_day', 'AFO_Start_IST_month', 'AFO_Start_IST_week', 'AFO_Ende_IST_dow', 'AFO_Ende_IST_hour', 'AFO_Ende_IST_day', 'AFO_Ende_IST_month', 'AFO_Ende_IST_week']\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 790\n",
      "[LightGBM] [Info] Number of data points in the train set: 1114960, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 265.886915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/burak1/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "\n",
      "===== MODEL PERFORMANCE =====\n",
      "MAE Tage: 28.093231956267584\n",
      "MSE Tage^2: 2784.5081983212776\n",
      "RÂ²: 0.8824742480996244\n",
      "ðŸ“¦ Saved: models/lightgbm/pipeline/lightgbm_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "from src.data.load_data import load_data\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# =============================\n",
    "# Konstanten\n",
    "# =============================\n",
    "TARGET_END = \"Auftragsende_IST\"\n",
    "START_COL = \"Auftragseingang\"\n",
    "\n",
    "DATE_COLS = [\n",
    "    \"Auftragseingang\",\n",
    "    \"Auftragsende_SOLL\",\n",
    "    \"AFO_Start_SOLL\",\n",
    "    \"AFO_Ende_SOLL\",\n",
    "    \"AFO_Start_IST\",\n",
    "    \"AFO_Ende_IST\",\n",
    "]\n",
    "\n",
    "# =============================\n",
    "# Daten laden\n",
    "# =============================\n",
    "data = load_data()\n",
    "\n",
    "print(\"Original Spalten:\", list(data.columns))\n",
    "\n",
    "# -----------------------------\n",
    "# Datums-Spalten parsen\n",
    "# -----------------------------\n",
    "for col in DATE_COLS:\n",
    "    data[col] = pd.to_datetime(data[col], errors=\"coerce\")\n",
    "\n",
    "# Target\n",
    "data[TARGET_END] = pd.to_datetime(data[TARGET_END], errors=\"coerce\")\n",
    "\n",
    "# Valid rows\n",
    "mask_valid = (~data[TARGET_END].isna()) & (~data[START_COL].isna())\n",
    "data = data[mask_valid].copy()\n",
    "\n",
    "start_dt = data[START_COL]\n",
    "\n",
    "# =============================\n",
    "# Dauer in Tagen berechnen\n",
    "# =============================\n",
    "duration_days = (data[TARGET_END] - start_dt).dt.total_seconds() / 86400.0\n",
    "duration_days = duration_days.astype(\"float32\")\n",
    "y = duration_days\n",
    "\n",
    "# =============================\n",
    "# Date-features extrahieren\n",
    "# =============================\n",
    "for col in DATE_COLS:\n",
    "    data[f\"{col}_dow\"] = data[col].dt.dayofweek\n",
    "    data[f\"{col}_hour\"] = data[col].dt.hour\n",
    "    data[f\"{col}_day\"] = data[col].dt.day\n",
    "    data[f\"{col}_month\"] = data[col].dt.month\n",
    "    data[f\"{col}_week\"] = data[col].dt.isocalendar().week.astype(int)\n",
    "\n",
    "# Original datetime-Spalten entfernen\n",
    "data = data.drop(columns=DATE_COLS + [TARGET_END])\n",
    "\n",
    "# =============================\n",
    "# ID-Spalten entfernen (vermeidet Overfitting)\n",
    "# =============================\n",
    "DROP_IDS = [\"AuftragsID\", \"BauteilID\", \"MaschinenID\"]\n",
    "for col in DROP_IDS:\n",
    "    if col in data.columns:\n",
    "        data = data.drop(columns=[col])\n",
    "\n",
    "# =============================\n",
    "# Feature-Typen bestimmen\n",
    "# =============================\n",
    "categorical = data.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numeric = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"KATEGORIEN:\", categorical)\n",
    "print(\"NUMERISCH:\", numeric)\n",
    "\n",
    "# =============================\n",
    "# Train/Test Split\n",
    "# =============================\n",
    "X_train, X_test, y_train, y_test, start_train_dt, start_test_dt = train_test_split(\n",
    "    data, y, start_dt, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# =============================\n",
    "# Preprocessing\n",
    "# =============================\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)),\n",
    "])\n",
    "\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", cat_pipeline, categorical),\n",
    "        (\"num\", num_pipeline, numeric),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# =============================\n",
    "# LightGBM Modell\n",
    "# =============================\n",
    "lgbm_model = LGBMRegressor(\n",
    "    n_estimators=470,\n",
    "    learning_rate=0.025,\n",
    "\n",
    "    num_leaves=256,\n",
    "    max_depth=10,\n",
    "\n",
    "    min_data_in_leaf=30,\n",
    "\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.3,\n",
    "\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", lgbm_model),\n",
    "])\n",
    "\n",
    "# =============================\n",
    "# Train\n",
    "# =============================\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "preds_days = pipe.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mae = mean_absolute_error(y_test, preds_days)\n",
    "mse = mean_squared_error(y_test, preds_days)\n",
    "r2 = r2_score(y_test, preds_days)\n",
    "\n",
    "print(\"\\n===== MODEL PERFORMANCE =====\")\n",
    "print(\"MAE Tage:\", mae)\n",
    "print(\"MSE Tage^2:\", mse)\n",
    "print(\"RÂ²:\", r2)\n",
    "\n",
    "# =============================\n",
    "# Speichern\n",
    "# =============================\n",
    "out_dir = \"models/lightgbm/pipeline\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(out_dir, \"lightgbm_pipeline.pkl\")\n",
    "joblib.dump(pipe, model_path)\n",
    "\n",
    "print(\"ðŸ“¦ Saved:\", model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
